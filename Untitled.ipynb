{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:07:25.235817Z",
     "start_time": "2020-11-21T17:07:23.739744Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('archive'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:07:27.429498Z",
     "start_time": "2020-11-21T17:07:25.237814Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image, ImageOps  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "#import plotly.graph_objects as go\n",
    "#import plotly.express as px\n",
    "import datetime\n",
    "#from plotly.offline import init_notebook_mode, iplot\n",
    "#import plotly.io as pio\n",
    "#pio.templates.default = 'plotly_white'\n",
    "#from plotly.subplots import make_subplots\n",
    "#init_notebook_mode(connected=True)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Concatenate, Flatten, MaxPooling2D, Conv2D\n",
    "from  tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#import tensorflow_addons as tfa\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import metrics\n",
    "import efficientnet.tfkeras as efn\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:07:27.471722Z",
     "start_time": "2020-11-21T17:07:27.431272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading through the metadata\n",
    "summary = pd.read_csv('archive/Chest_xray_Corona_dataset_Summary.csv')\n",
    "df = pd.read_csv('archive/Chest_xray_Corona_Metadata.csv')\n",
    "print(df.head())\n",
    "\n",
    "replace_dict = {'Pnemonia':1,\n",
    "                'Normal':0}\n",
    "df['Label'] = df['Label'].replace(replace_dict)\n",
    "\n",
    "train_df = df[df.Dataset_type=='TRAIN']\n",
    "print(train_df.head())\n",
    "test_df = df[df.Dataset_type=='TEST']\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:07:27.478029Z",
     "start_time": "2020-11-21T17:07:27.473402Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inside the Pneumonia idagnosed data how many are covid positive\n",
    "df_pneumonia = df[df.Label==1]\n",
    "df_pneumonia_covid = df_pneumonia[df_pneumonia.Label_2_Virus_category=='COVID-19']\n",
    "pneumonia_covid_images = df_pneumonia_covid.X_ray_image_name.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:07:27.482074Z",
     "start_time": "2020-11-21T17:07:27.479564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the path to Train and Test directories\n",
    "training_data_path = 'archive/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n",
    "testing_data_path = 'archive/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:07:27.486933Z",
     "start_time": "2020-11-21T17:07:27.483767Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funtions for Making nd Removing subdirectories\n",
    "def create_dir():\n",
    "    try:\n",
    "        os.makedirs('archive/working/train/Pneumonia')\n",
    "        os.makedirs('archive/working/train/Normal')\n",
    "        os.makedirs('archive/working/test/Pneumonia')\n",
    "        os.makedirs('archive/working/test/Normal')\n",
    "    except:\n",
    "        pass\n",
    "def remove_dir():\n",
    "    try:\n",
    "        shutil.rmtree('archive/working/train')\n",
    "        shutil.rmtree('archive/working/test')    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:07:27.494406Z",
     "start_time": "2020-11-21T17:07:27.488441Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seperate dataframes for different labels in test and train\n",
    "train_pneumonia_df = train_df[train_df.Label==1]\n",
    "train_normal_df = train_df[train_df.Label==0]\n",
    "test_pneumonia_df = test_df[test_df.Label==1]\n",
    "test_normal_df = test_df[test_df.Label==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:07:29.499541Z",
     "start_time": "2020-11-21T17:07:27.495919Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copying the files to newly created locations. You may use Flow from dataframe attribute and skip all these steps. But I prefer to use flow from directory \n",
    "remove_dir()\n",
    "create_dir()\n",
    "\n",
    "training_images_pneumonia = train_pneumonia_df.X_ray_image_name.values.tolist()\n",
    "training_images_normal = train_normal_df.X_ray_image_name.values.tolist()\n",
    "testing_images_pneumonia = test_pneumonia_df.X_ray_image_name.values.tolist()\n",
    "testing_images_normal = test_normal_df.X_ray_image_name.values.tolist()\n",
    "\n",
    "for image in training_images_pneumonia:\n",
    "    train_image_pneumonia = os.path.join(training_data_path, str(image))\n",
    "    shutil.copy(train_image_pneumonia, 'archive/working/train/Pneumonia')\n",
    "    \n",
    "for image in training_images_normal:\n",
    "    train_image_normal = os.path.join(training_data_path, str(image))\n",
    "    shutil.copy(train_image_normal, 'archive/working/train/Normal')\n",
    "    \n",
    "for image in testing_images_pneumonia:\n",
    "    test_image_pneumonia = os.path.join(testing_data_path, str(image))\n",
    "    shutil.copy(test_image_pneumonia, 'archive/working/test/Pneumonia')\n",
    "    \n",
    "for image in testing_images_normal:\n",
    "    test_image_normal = os.path.join(testing_data_path, str(image))\n",
    "    shutil.copy(test_image_normal, 'archive/working/test/Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:07:29.505116Z",
     "start_time": "2020-11-21T17:07:29.501461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "batch_size = 64\n",
    "img_width, img_height, img_num_channels = 224,224,3\n",
    "no_epochs = 15\n",
    "verbosity = 1\n",
    "input_shape = (img_width, img_height, img_num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:07:40.051795Z",
     "start_time": "2020-11-21T17:07:29.506634Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(input_shape)\n",
    "#Creating an EffNet model\n",
    "model_B7 = efn.EfficientNetB7(weights='imagenet', input_shape=input_shape, include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:07:40.071800Z",
     "start_time": "2020-11-21T17:07:40.054087Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()\n",
    "#from tensorflow.python.client import device_lib\n",
    "#device_lib.list_local_devices()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "tf.device('/CPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:08:07.362723Z",
     "start_time": "2020-11-21T17:07:40.073365Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to build, compile and train the model\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   rotation_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory('archive/working/train',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_generator = valid_datagen.flow_from_directory('archive/working/test',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "pretrained_model = model_B7\n",
    "pretrained_model.trainable=True\n",
    "set_trainable=False\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    if layer.name == 'block7c_project_conv':\n",
    "        set_trainable=True\n",
    "    if set_trainable:\n",
    "        layer.trainable=True\n",
    "    else:\n",
    "        layer.trainable=False\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "model.add(pretrained_model)\n",
    "model.add(MaxPooling2D(name=\"MaxPool_\"))\n",
    "model.add(Dropout(0.2, name=\"dropout_out\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=binary_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=[metrics.AUC(name='auc'), 'accuracy'])\n",
    "\n",
    "es_callback = EarlyStopping(monitor='val_auc', mode='max', patience=8,\n",
    "                                              verbose=1, min_delta=0.0001, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples//batch_size,\n",
    "                    epochs = no_epochs,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//batch_size,\n",
    "                    callbacks= [es_callback],\n",
    "                    verbose=verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:08:07.363767Z",
     "start_time": "2020-11-21T17:06:48.433Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting the evaluation metrics\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list(range(1,11)), y=history.history['auc'],\n",
    "                         line=dict(color='firebrick', width=2, dash='dash'), name='AUC'))\n",
    "fig.add_trace(go.Scatter(x=list(range(1,11)), y=history.history['val_auc'],\n",
    "                         line=dict(color='turquoise', width=2), name='validation AUC'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(1,11)), y=history.history['accuracy'],\n",
    "                         line=dict(color='orange', width=2, dash='dash'), name='accuracy'))\n",
    "fig.add_trace(go.Scatter(x=list(range(1,11)), y=history.history['val_accuracy'],\n",
    "                         line=dict(color='green', width=2), name='validation accuracy'))\n",
    "\n",
    "fig.update_layout(title_text='Plot of evaluation metrics', font_size=15, xaxis_title='Epochs')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
