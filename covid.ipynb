{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image, ImageOps  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'plotly_white'\n",
    "from plotly.subplots import make_subplots\n",
    "init_notebook_mode(connected=True)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Concatenate, Flatten, MaxPooling2D, Conv2D\n",
    "from  tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import metrics\n",
    "import efficientnet.tfkeras as efn\n",
    "from tqdm import tqdm_notebook\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading through the metadata\n",
    "summary = pd.read_csv('/kaggle/input/coronahack-chest-xraydataset/Chest_xray_Corona_dataset_Summary.csv')\n",
    "df = pd.read_csv('/kaggle/input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv')\n",
    "print(df.head())\n",
    "\n",
    "replace_dict = {'Pnemonia':1,\n",
    "                'Normal':0}\n",
    "df['Label'] = df['Label'].replace(replace_dict)\n",
    "\n",
    "train_df = df[df.Dataset_type=='TRAIN']\n",
    "print(train_df.head())\n",
    "test_df = df[df.Dataset_type=='TEST']\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['gold', 'mediumturquoise']\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=['Pneumonia', 'Normal'],\n",
    "                             values=[df.Label.value_counts()[1], df.Label.value_counts()[0]])])\n",
    "\n",
    "fig.update_traces(hoverinfo='label+value', textinfo='percent+label', textfont_size=20,\n",
    "                  marker=dict(colors=colors,\n",
    "                           line=dict(color='#000000',width=2)))\n",
    "fig.update_layout(title_text='Distributions of classes in the data', font_size=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inside the Pneumonia idagnosed data how many are covid positive\n",
    "df_pneumonia = df[df.Label==1]\n",
    "df_pneumonia_covid = df_pneumonia[df_pneumonia.Label_2_Virus_category=='COVID-19']\n",
    "pneumonia_covid_images = df_pneumonia_covid.X_ray_image_name.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path to Train and Test directories\n",
    "training_data_path = '../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n",
    "testing_data_path = '../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtions for Making nd Removing subdirectories\n",
    "def create_dir():\n",
    "    try:\n",
    "        os.makedirs('/kaggle/working/train/Pneumonia')\n",
    "        os.makedirs('/kaggle/working/train/Normal')\n",
    "        os.makedirs('/kaggle/working/test/Pneumonia')\n",
    "        os.makedirs('/kaggle/working/test/Normal')\n",
    "    except:\n",
    "        pass\n",
    "def remove_dir():\n",
    "    try:\n",
    "        shutil.rmtree('/kaggle/working/train')\n",
    "        shutil.rmtree('/kaggle/working/test')    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate dataframes for different labels in test and train\n",
    "train_pneumonia_df = train_df[train_df.Label==1]\n",
    "train_normal_df = train_df[train_df.Label==0]\n",
    "test_pneumonia_df = test_df[test_df.Label==1]\n",
    "test_normal_df = test_df[test_df.Label==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the files to newly created locations. You may use Flow from dataframe attribute and skip all these steps. But I prefer to use flow from directory \n",
    "remove_dir()\n",
    "create_dir()\n",
    "\n",
    "training_images_pneumonia = train_pneumonia_df.X_ray_image_name.values.tolist()\n",
    "training_images_normal = train_normal_df.X_ray_image_name.values.tolist()\n",
    "testing_images_pneumonia = test_pneumonia_df.X_ray_image_name.values.tolist()\n",
    "testing_images_normal = test_normal_df.X_ray_image_name.values.tolist()\n",
    "\n",
    "for image in training_images_pneumonia:\n",
    "    train_image_pneumonia = os.path.join(training_data_path, str(image))\n",
    "    shutil.copy(train_image_pneumonia, '/kaggle/working/train/Pneumonia')\n",
    "    \n",
    "for image in training_images_normal:\n",
    "    train_image_normal = os.path.join(training_data_path, str(image))\n",
    "    shutil.copy(train_image_normal, '/kaggle/working/train/Normal')\n",
    "    \n",
    "for image in testing_images_pneumonia:\n",
    "    test_image_pneumonia = os.path.join(testing_data_path, str(image))\n",
    "    shutil.copy(test_image_pneumonia, '/kaggle/working/test/Pneumonia')\n",
    "    \n",
    "for image in testing_images_normal:\n",
    "    test_image_normal = os.path.join(testing_data_path, str(image))\n",
    "    shutil.copy(test_image_normal, '/kaggle/working/test/Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualaiCzing the Pneumonia affected Xrays\n",
    "plt.figure(figsize=(12,12))\n",
    "for index, fn in enumerate(training_images_pneumonia[:4]):\n",
    "    path = '/kaggle/working/train/Pneumonia/' + str(fn)\n",
    "    image = Image.open(path)\n",
    "    image = ImageOps.grayscale(image)\n",
    "    image.thumbnail((224,224))\n",
    "    plt.subplot(2,2,index+1)\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualaiCzing the Normal  Xrays\n",
    "plt.figure(figsize=(12,12))\n",
    "for index, fn in enumerate(training_images_normal[:4]):\n",
    "    path = '/kaggle/working/train/Normal/' + str(fn)\n",
    "    image = Image.open(path)\n",
    "    image = ImageOps.grayscale(image)\n",
    "    image.thumbnail((224,224))\n",
    "    plt.subplot(2,2,index+1)\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "batch_size = 64\n",
    "img_width, img_height, img_num_channels = 224,224,3\n",
    "no_epochs = 15\n",
    "verbosity = 1\n",
    "input_shape = (img_width, img_height, img_num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an EffNet model\n",
    "model_B7 = efn.EfficientNetB7(weights='imagenet', input_shape=input_shape, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_B7 = tf.keras.applications.NASNetLarge(\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     #input_tensor=None,\n",
    "#     input_shape=input_shape,\n",
    "#     pooling=None,\n",
    "#     classes=1000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Input\n",
    "# model_B7 = tf.keras.applications.NASNetLarge(\n",
    "#     input_shape=None,\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_tensor=Input(shape=input_shape),\n",
    "#     pooling=None,\n",
    "#     classes=1000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build, compile and train the model\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   rotation_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/working/train',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_generator = valid_datagen.flow_from_directory('/kaggle/working/test',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "pretrained_model = model_B7\n",
    "pretrained_model.trainable=True\n",
    "set_trainable=False\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    if layer.name == 'block7c_project_conv':\n",
    "        set_trainable=True\n",
    "    if set_trainable:\n",
    "        layer.trainable=True\n",
    "    else:\n",
    "        layer.trainable=False\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "model.add(pretrained_model)\n",
    "model.add(MaxPooling2D(name=\"MaxPool_\"))\n",
    "model.add(Dropout(0.2, name=\"dropout_out\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=binary_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=[metrics.AUC(name='auc'), 'accuracy'])\n",
    "\n",
    "es_callback = EarlyStopping(monitor='val_auc', mode='max', patience=8,\n",
    "                                              verbose=1, min_delta=0.0001, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples//batch_size,\n",
    "                    epochs = no_epochs,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//batch_size,\n",
    "                    callbacks= [es_callback],\n",
    "                    verbose=verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the evaluation metrics\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list(range(1,11)), y=history.history['auc'],\n",
    "                         line=dict(color='firebrick', width=2, dash='dash'), name='AUC'))\n",
    "fig.add_trace(go.Scatter(x=list(range(1,11)), y=history.history['val_auc'],\n",
    "                         line=dict(color='turquoise', width=2), name='validation AUC'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(1,11)), y=history.history['accuracy'],\n",
    "                         line=dict(color='orange', width=2, dash='dash'), name='accuracy'))\n",
    "fig.add_trace(go.Scatter(x=list(range(1,11)), y=history.history['val_accuracy'],\n",
    "                         line=dict(color='green', width=2), name='validation accuracy'))\n",
    "\n",
    "fig.update_layout(title_text='Plot of evaluation metrics', font_size=15, xaxis_title='Epochs')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
